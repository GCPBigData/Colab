{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     10\n",
       "4     53\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "8     18\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vinho_bom'] = data['quality'].map(lambda x: 0 if x < 7 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>vinho_bom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  vinho_bom  \n",
       "0      9.4        5          0  \n",
       "1      9.8        5          0  \n",
       "2      9.8        5          0  \n",
       "3      9.8        6          0  \n",
       "4      9.4        5          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mboosting_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbdt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample_for_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_split_gain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_child_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreg_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : string, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, -1 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : string, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequence of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If None, default seeds in C++ code will be used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : string, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    Note\n",
       "    ----\n",
       "    \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "n_features_ : int\n",
       "    The number of features of fitted model.\n",
       "classes_ : array of shape = [n_classes]\n",
       "    The class label array (only for classification problem).\n",
       "n_classes_ : int\n",
       "    The number of classes (only for classification problem).\n",
       "best_score_ : dict or None\n",
       "    The best score of fitted model.\n",
       "best_iteration_ : int or None\n",
       "    The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
       "objective_ : string or callable\n",
       "    The concrete objective used while fitting this model.\n",
       "booster_ : Booster\n",
       "    The underlying Booster of this model.\n",
       "evals_result_ : dict or None\n",
       "    The evaluation results if ``early_stopping_rounds`` has been specified.\n",
       "feature_importances_ : array of shape = [n_features]\n",
       "    The feature importances (the higher, the more important the feature).\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "    group : array-like\n",
       "        Group/query data, used for ranking task.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the gradient for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second derivative for each sample point.\n",
       "\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data.iloc[:, :-2], data['vinho_bom'], train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((799, 11), (800, 11), (799,), (800,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.081</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99628</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1196</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99840</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1179</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.99599</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1214           10.2              0.33         0.46             1.9      0.081   \n",
       "1196            7.9              0.58         0.23             2.3      0.076   \n",
       "227             9.0              0.82         0.14             2.6      0.089   \n",
       "1179            8.2              0.35         0.33             2.4      0.076   \n",
       "425             6.6              0.84         0.03             2.3      0.059   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1214                  6.0                   9.0  0.99628  3.10       0.48   \n",
       "1196                 23.0                  94.0  0.99686  3.21       0.58   \n",
       "227                   9.0                  23.0  0.99840  3.39       0.63   \n",
       "1179                 11.0                  47.0  0.99599  3.27       0.81   \n",
       "425                  32.0                  48.0  0.99520  3.52       0.56   \n",
       "\n",
       "      alcohol  \n",
       "1214     10.4  \n",
       "1196      9.5  \n",
       "227       9.8  \n",
       "1179     11.0  \n",
       "425      12.3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 * 10 * 10 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = LGBMClassifier(random_state=0)\n",
    "mdl.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "p = mdl.predict_proba(Xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8882241486710964"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search - busca aleatória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, 2, 3, 4, 5 - [1,2,3,4,5] -> [2], [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import dummy_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdummy_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Random search by uniform sampling within the given bounds.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "* `func` [callable]:\n",
       "    Function to minimize. Should take a single list of parameters\n",
       "    and return the objective value.\n",
       "\n",
       "    If you have a search-space where all dimensions have names,\n",
       "    then you can use `skopt.utils.use_named_args` as a decorator\n",
       "    on your objective function, in order to call it directly\n",
       "    with the named arguments. See `use_named_args` for an example.\n",
       "\n",
       "* `dimensions` [list, shape=(n_dims,)]:\n",
       "    List of search space dimensions.\n",
       "    Each search dimension can be defined either as\n",
       "\n",
       "    - a `(lower_bound, upper_bound)` tuple (for `Real` or `Integer`\n",
       "      dimensions),\n",
       "    - a `(lower_bound, upper_bound, prior)` tuple (for `Real`\n",
       "      dimensions),\n",
       "    - as a list of categories (for `Categorical` dimensions), or\n",
       "    - an instance of a `Dimension` object (`Real`, `Integer` or\n",
       "      `Categorical`).\n",
       "\n",
       "* `n_calls` [int, default=100]:\n",
       "    Number of calls to `func` to find the minimum.\n",
       "\n",
       "* `x0` [list, list of lists or `None`]:\n",
       "    Initial input points.\n",
       "\n",
       "    - If it is a list of lists, use it as a list of input points.\n",
       "    - If it is a list, use it as a single initial input point.\n",
       "    - If it is `None`, no initial input points are used.\n",
       "\n",
       "* `y0` [list, scalar or `None`]:\n",
       "    Evaluation of initial input points.\n",
       "\n",
       "    - If it is a list, then it corresponds to evaluations of the function\n",
       "      at each element of `x0` : the i-th element of `y0` corresponds\n",
       "      to the function evaluated at the i-th element of `x0`.\n",
       "    - If it is a scalar, then it corresponds to the evaluation of the\n",
       "      function at `x0`.\n",
       "    - If it is None and `x0` is provided, then the function is evaluated\n",
       "      at each element of `x0`.\n",
       "\n",
       "* `random_state` [int, RandomState instance, or None (default)]:\n",
       "    Set random state to something other than None for reproducible\n",
       "    results.\n",
       "\n",
       "* `verbose` [boolean, default=False]:\n",
       "    Control the verbosity. It is advised to set the verbosity to True\n",
       "    for long optimization runs.\n",
       "\n",
       "* `callback` [callable, list of callables, optional]\n",
       "    If callable then `callback(res)` is called after each call to `func`.\n",
       "    If list of callables, then each callable in the list is called.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "* `res` [`OptimizeResult`, scipy object]:\n",
       "    The optimization result returned as a OptimizeResult object.\n",
       "    Important attributes are:\n",
       "\n",
       "    - `x` [list]: location of the minimum.\n",
       "    - `fun` [float]: function value at the minimum.\n",
       "    - `x_iters` [list of lists]: location of function evaluation for each\n",
       "       iteration.\n",
       "    - `func_vals` [array]: function value for each iteration.\n",
       "    - `space` [Space]: the optimisation space.\n",
       "    - `specs` [dict]: the call specifications.\n",
       "    - `rng` [RandomState instance]: State of the random state\n",
       "       at the end of minimization.\n",
       "\n",
       "    For more details related to the OptimizeResult object, refer\n",
       "    http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/skopt/optimizer/dummy.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?dummy_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.09871192514273254, 74, 10, 0.3372159440002478, 0.23208030173540176] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.3388\n",
      "Function value obtained: -0.8870\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.001529949829431263, 78, 72, 0.3782826906908954, 0.457090726807603] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0598\n",
      "Function value obtained: -0.8382\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.01195730942971637, 128, 19, 0.5483207515942279, 0.49910760440160107] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.1734\n",
      "Function value obtained: -0.8831\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.0028784217488024557, 16, 51, 0.9182639233502714, 0.5114843271882895] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0680\n",
      "Function value obtained: -0.8693\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.007267702383040958, 96, 97, 0.7894697745197069, 0.7443734643715278] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1229\n",
      "Function value obtained: -0.8449\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.04031948793713315, 63, 23, 0.5422449214947946, 0.8785182267810852] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 0.1774\n",
      "Function value obtained: -0.8848\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.045529597892867466, 90, 14, 0.30939747550591, 0.15331888117140713] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 0.1103\n",
      "Function value obtained: -0.8573\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.021930881089764206, 73, 4, 0.6880713925510277, 0.47060909107214777] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 0.7645\n",
      "Function value obtained: -0.8870\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.002483715204721354, 26, 44, 0.7021758812975045, 0.8511631047076357] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 0.1253\n",
      "Function value obtained: -0.8583\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0010878688833867167, 43, 83, 0.98941803446117, 0.7733490889418555] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 0.0877\n",
      "Function value obtained: -0.8445\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.003638211850540798, 89, 8, 0.14806470624875995, 0.5031041735583147] \n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 0.1718\n",
      "Function value obtained: -0.8600\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.06564339077069616, 105, 24, 0.163515944581681, 0.572319439183401] \n",
      "\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 0.0539\n",
      "Function value obtained: -0.8700\n",
      "Current minimum: -0.8870\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.0014697585967435188, 40, 9, 0.9149259627034465, 0.36903710098874454] \n",
      "\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 0.5468\n",
      "Function value obtained: -0.8889\n",
      "Current minimum: -0.8889\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.014749532034944692, 89, 26, 0.633241401906253, 0.9608820910034701] \n",
      "\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 0.1683\n",
      "Function value obtained: -0.8884\n",
      "Current minimum: -0.8889\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.0033262735259356143, 34, 89, 0.5567760660749166, 0.9549443246793757] \n",
      "\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 0.1316\n",
      "Function value obtained: -0.8403\n",
      "Current minimum: -0.8889\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.009685436253688836, 2, 78, 0.09307844214592059, 0.225969507272543] \n",
      "\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 0.0648\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8889\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.03844210597293627, 93, 22, 0.8889692020284521, 0.5867093706408683] \n",
      "\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 0.2034\n",
      "Function value obtained: -0.8924\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.00786973960931508, 45, 21, 0.40870512409353993, 0.5845822248519866] \n",
      "\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 0.1752\n",
      "Function value obtained: -0.8760\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.020164978538544195, 59, 83, 0.6559446598566927, 0.2136833965403995] \n",
      "\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 0.0375\n",
      "Function value obtained: -0.8770\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.024010940718920456, 9, 25, 0.3814534248789504, 0.3429351025885235] \n",
      "\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 0.1535\n",
      "Function value obtained: -0.8839\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 21 started. Evaluating function at random point.\n",
      "[0.061911658253265375, 96, 61, 0.9665980447909663, 0.6970973480366033] \n",
      "\n",
      "Iteration No: 21 ended. Evaluation done at random point.\n",
      "Time taken: 0.1917\n",
      "Function value obtained: -0.8917\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 22 started. Evaluating function at random point.\n",
      "[0.01751424579956557, 110, 93, 0.9520147957717178, 0.5049209201319466] \n",
      "\n",
      "Iteration No: 22 ended. Evaluation done at random point.\n",
      "Time taken: 0.0757\n",
      "Function value obtained: -0.8664\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 23 started. Evaluating function at random point.\n",
      "[0.014347598955915168, 84, 87, 0.27517563123087635, 0.9130415685060285] \n",
      "\n",
      "Iteration No: 23 ended. Evaluation done at random point.\n",
      "Time taken: 0.0945\n",
      "Function value obtained: -0.8629\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 24 started. Evaluating function at random point.\n",
      "[0.014039737029591284, 17, 6, 0.6362876679396877, 0.3939804115948866] \n",
      "\n",
      "Iteration No: 24 ended. Evaluation done at random point.\n",
      "Time taken: 0.2663\n",
      "Function value obtained: -0.8844\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 25 started. Evaluating function at random point.\n",
      "[0.011327034010293172, 103, 14, 0.3894062720023748, 0.9176816358278194] \n",
      "\n",
      "Iteration No: 25 ended. Evaluation done at random point.\n",
      "Time taken: 0.2153\n",
      "Function value obtained: -0.8819\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 26 started. Evaluating function at random point.\n",
      "[0.017649005221070314, 98, 56, 0.9329653720565734, 0.7218072257652316] \n",
      "\n",
      "Iteration No: 26 ended. Evaluation done at random point.\n",
      "Time taken: 0.1263\n",
      "Function value obtained: -0.8812\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 27 started. Evaluating function at random point.\n",
      "[0.09877469581360704, 123, 84, 0.18027896214743389, 0.9393359167334473] \n",
      "\n",
      "Iteration No: 27 ended. Evaluation done at random point.\n",
      "Time taken: 0.0571\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 28 started. Evaluating function at random point.\n",
      "[0.024753483395116363, 45, 7, 0.7676898999723432, 0.7784885696151218] \n",
      "\n",
      "Iteration No: 28 ended. Evaluation done at random point.\n",
      "Time taken: 0.6720\n",
      "Function value obtained: -0.8861\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 29 started. Evaluating function at random point.\n",
      "[0.07015345605895347, 11, 67, 0.16805741387355647, 0.11789212045581604] \n",
      "\n",
      "Iteration No: 29 ended. Evaluation done at random point.\n",
      "Time taken: 0.0995\n",
      "Function value obtained: -0.7909\n",
      "Current minimum: -0.8924\n",
      "Iteration No: 30 started. Evaluating function at random point.\n",
      "[0.0011282932078263237, 23, 41, 0.28390051422289364, 0.8740251538145993] \n",
      "\n",
      "Iteration No: 30 ended. Evaluation done at random point.\n",
      "Time taken: 0.0878\n",
      "Function value obtained: -0.8398\n",
      "Current minimum: -0.8924\n"
     ]
    }
   ],
   "source": [
    "def treinar_modelo(params):\n",
    "    learning_rate = params[0]\n",
    "    num_leaves = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    \n",
    "    print(params, '\\n')\n",
    "    \n",
    "    mdl = LGBMClassifier(learning_rate=learning_rate, num_leaves=num_leaves, min_child_samples=min_child_samples,\n",
    "                        subsample=subsample, colsample_bytree=colsample_bytree, random_state=0, subsample_freq=1, \n",
    "                         n_estimators=100)\n",
    "    mdl.fit(Xtrain, ytrain)\n",
    "    \n",
    "    p = mdl.predict_proba(Xtest)[:,1]\n",
    "    \n",
    "    return -roc_auc_score(ytest, p)\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), #learning rate\n",
    "         (2, 128), # num_leaves\n",
    "         (1, 100), # min_child_samples\n",
    "         (0.05, 1.0), # subsample\n",
    "         (0.1, 1.0)] # colsample bytree\n",
    "\n",
    "resultado = dummy_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03844210597293627, 93, 22, 0.8889692020284521, 0.5867093706408683]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc = 0.8924 - [0.03844210597293627, 93, 22, 0.8889692020284521, 0.5867093706408683]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.03844210597293627, 93, 22, 0.8889692020284521, 0.5867093706408683] -> 0.8924\n",
    "[0.0011282932078263237, 23, 41, 0.28390051422289364, 0.8740251538145993] -> 0.8398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.09871192514273254, 120, 14, 0.9990884895579377, 0.3124800792567785] \n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.6467\n",
      "Function value obtained: -0.8849\n",
      "Current minimum: -0.8849\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.006210998932353835, 51, 67, 0.9387621172657304, 0.8616798250174156] \n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.1594\n",
      "Function value obtained: -0.8577\n",
      "Current minimum: -0.8849\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.004232013397179603, 68, 45, 0.2680983530433343, 0.5809725180523154] \n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0904\n",
      "Function value obtained: -0.8380\n",
      "Current minimum: -0.8849\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.0672858974212934, 60, 44, 0.9421713999524447, 0.8005503127028804] \n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.2128\n",
      "Function value obtained: -0.8941\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.027035912483147396, 103, 10, 0.5422449214947946, 0.8785182267810853] \n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.3326\n",
      "Function value obtained: -0.8928\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.045529597892867466, 107, 28, 0.1062810412364853, 0.7034752360620511] \n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 0.0984\n",
      "Function value obtained: -0.8589\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.01535080081765723, 87, 42, 0.23767335308554222, 0.3606666764912312] \n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 0.0644\n",
      "Function value obtained: -0.8714\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.0019241559628256106, 101, 42, 0.0824627456265471, 0.661626987829618] \n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 0.0633\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.02095421812724112, 40, 45, 0.2610183201586061, 0.16602775456833962] \n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 0.1708\n",
      "Function value obtained: -0.8748\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.008679147174590262, 14, 90, 0.163515944581681, 0.5723194391834011] \n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 0.4684\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "[0.1, 116, 1, 0.27627985375349373, 1.0] \n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4653\n",
      "Function value obtained: -0.8902\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "[0.025444350810007958, 128, 25, 0.26042234987949886, 0.5768928304273598] \n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5038\n",
      "Function value obtained: -0.8660\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "[0.1, 71, 17, 0.9462393181112093, 0.7282723942281502] \n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9562\n",
      "Function value obtained: -0.8899\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "[0.1, 119, 86, 0.2822133948472298, 0.1] \n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4031\n",
      "Function value obtained: -0.8751\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "[0.1, 108, 93, 0.11493410263220662, 0.22563776171725936] \n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4700\n",
      "Function value obtained: -0.5000\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "[0.1, 11, 100, 0.5105256446472684, 0.44993638684509685] \n",
      "\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5118\n",
      "Function value obtained: -0.8847\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "[0.1, 100, 1, 0.14789315913309667, 0.7920254048327372] \n",
      "\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4094\n",
      "Function value obtained: -0.8511\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "[0.1, 92, 75, 0.3925699487943026, 0.7140554697356464] \n",
      "\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5232\n",
      "Function value obtained: -0.8739\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "[0.1, 116, 48, 0.6930154231519196, 0.3607008463687954] \n",
      "\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4508\n",
      "Function value obtained: -0.8874\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "[0.0038228834819648253, 15, 1, 0.7184097640007497, 0.7325009107938859] \n",
      "\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8674\n",
      "Function value obtained: -0.8629\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.0018380866330314188, 77, 66, 0.6018684662387099, 0.24828226647323948] \n",
      "\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7032\n",
      "Function value obtained: -0.8708\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.1, 10, 100, 0.7821291696269489, 0.848165947341192] \n",
      "\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6866\n",
      "Function value obtained: -0.8940\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.1, 128, 29, 0.18241425588288668, 0.7089095188314459] \n",
      "\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5962\n",
      "Function value obtained: -0.8708\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.001, 52, 1, 1.0, 0.8646218599153686] \n",
      "\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4751\n",
      "Function value obtained: -0.8507\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.001, 90, 100, 0.7568327134116001, 0.3652626850970506] \n",
      "\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5180\n",
      "Function value obtained: -0.8480\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.001, 24, 1, 0.44834016303688007, 0.17553093815745677] \n",
      "\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7782\n",
      "Function value obtained: -0.8462\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.1, 128, 70, 0.3140217529792546, 0.1] \n",
      "\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5065\n",
      "Function value obtained: -0.8841\n",
      "Current minimum: -0.8941\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.1, 118, 1, 0.41832604811717616, 0.8614352657429701] \n",
      "\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0914\n",
      "Function value obtained: -0.8991\n",
      "Current minimum: -0.8991\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.1, 102, 100, 1.0, 0.14345294140758985] \n",
      "\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5513\n",
      "Function value obtained: -0.8699\n",
      "Current minimum: -0.8991\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.1, 94, 100, 0.6528809266945954, 0.26145558515649425] \n",
      "\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5726\n",
      "Function value obtained: -0.8838\n",
      "Current minimum: -0.8991\n"
     ]
    }
   ],
   "source": [
    "resultados_gp = gp_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30, n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc917ce3c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(resultado, resultados_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration exploitation tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 118, 1, 0.41832604811717616, 0.8614352657429701]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc = 0.8924 - [0.03844210597293627, 93, 22, 0.8889692020284521, 0.5867093706408683]\n",
    "# auc = 0.8991 - [0.1, 118, 1, 0.41832604811717616, 0.8614352657429701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
