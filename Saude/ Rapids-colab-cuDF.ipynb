{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Rapids-colab-cuDF.ipynb","provenance":[{"file_id":"1XlHI8MKDl7Y-ko8Td9y6-ROh-AHclgg7","timestamp":1592301242076},{"file_id":"1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0","timestamp":1579746934539},{"file_id":"1XTKHiIcvyL5nuldx0HSL_dUa8yopzy_Y","timestamp":1568928635382},{"file_id":"1gUnPS2zuUOUe4YG-2iDm_Y2X5RTkgsGh","timestamp":1556293046020}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"scfLT2i0MLyD","colab_type":"text"},"source":["# Environment Sanity Check #\n","\n","Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n","\n","Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4, P4 or P100."]},{"cell_type":"code","metadata":{"id":"B0C8IV5TQnjN","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CtNdk7PSafKP","colab_type":"text"},"source":["#Setup Rapids:\n","Set up script installs\n","1. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n","1. removes incompatible files\n","1. Install RAPIDS libraries\n","1. Set necessary environment variables\n","1. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions"]},{"cell_type":"code","metadata":{"id":"m0jdXBRiDSzj","colab_type":"code","outputId":"d77da9e0-c7b0-46cb-b8d9-cd67b3d9babd","executionInfo":{"status":"ok","timestamp":1592303319210,"user_tz":240,"elapsed":8220,"user":{"displayName":"Jose RF Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcwNPZv9MqlX3Lmsf8p1-yLZLhGugUqwvtRlHlAm0=s64","userId":"00996655643077345002"}},"colab":{"base_uri":"https://localhost:8080/","height":887}},"source":["# Install RAPIDS\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!bash rapidsai-csp-utils/colab/rapids-colab.sh\n","\n","import sys, os\n","\n","dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n","sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n","sys.path\n","exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n","PLEASE READ\n","********************************************************************************************************\n","Changes:\n","1. Default stable version is now 0.14.  Nightly is now 0.15.  We have fixed the long conda install.  Hooray!\n","2. For stable releases, we now use static yml files, in case of incompatible dependancy changes later.\n","3. You can now declare your RAPIDSAI version as a CLI option and skip the user prompts (ex: '0.14' or '0.15', between 0.13 to 0.15, without the quotes): \n","        \"!bash rapidsai-csp-utils/colab/rapids-colab.sh <version/label>\"\n","        Examples: '!bash rapidsai-csp-utils/colab/rapids-colab.sh 0.14', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh stable', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh s'\n","                  '!bash rapidsai-csp-utils/colab/rapids-colab.sh 0.15, or '!bash rapidsai-csp-utils/colab/rapids-colab.sh nightly', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh n'\n","Enjoy using RAPIDS!  If you have any issues with or suggestions for RAPIDSAI on Colab, please create a bug request on https://github.com/rapidsai/rapidsai-csp-utils/issues/new.  Thanks!\n","As you didn't specify a RAPIDS version, please enter in the box your desired RAPIDS version (ex: '0.11' or '0.12', between 0.13 to 0.15, without the quotes)\n","and hit Enter. If you need stability, use 0.14. If you want bleeding edge, use our nightly version (0.15), but understand that caveats that come with nightly versions.\n","yes\n","RAPIDS Version modified to 0.13 stable\n","Checking for GPU type:\n","Traceback (most recent call last):\n","  File \"rapidsai-csp-utils/colab/env-check.py\", line 25, in <module>\n","    \"\"\")\n","Exception: \n","    Unfortunately Colab didn't give you a T4, P4, or P100 GPU.\n","    \n","    Make sure you've configured Colab to request a GPU instance type.\n","    \n","    If you get a different GPU, try Runtime -> Reset all runtimes...\n","  \n","\n","************************************************\n","Your Google Colab instance has RAPIDS installed!\n","************************************************\n","***********************************************************************\n","Let us check on those pyarrow and cffi versions...\n","***********************************************************************\n","\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","unloaded pyarrow 0.14.1\n","loaded pyarrow 0.15.0\n","You're now running pyarrow 0.15.0 and are good to go!\n","unloaded cffi 1.14.0\n","loaded cffi 1.11.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"REixcABw7n8k","colab_type":"text"},"source":["# Setup Spark"]},{"cell_type":"code","metadata":{"id":"QTmb0l4o58_r","colab_type":"code","colab":{}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://www-us.apache.org/dist/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop3.2.tgz\n","!tar -xvf spark-3.0.0-preview2-bin-hadoop3.2.tgz\n","!pip install -q findspark"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xwjDVOG875Sy","colab_type":"code","colab":{}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-preview2-bin-hadoop3.2\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXkE84AmFxOP","colab_type":"code","colab":{}},"source":["!wget -O test.csv -q https://zenodo.org/record/2595588/files/all-sorted-2018-01-21-to-2019-02-04.csv?download=1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9oOCJ4NYMjY7","colab_type":"text"},"source":["# cuDF compare to pandas DF #\n","\n","Now you can run code! \n","\n","What follows are basic examples where all processing takes place on the GPU."]},{"cell_type":"markdown","metadata":{"id":"V38dg-oUJtEO","colab_type":"text"},"source":["#[cuDF](https://github.com/rapidsai/cudf)#\n","\n","Load a dataset into a GPU memory resident DataFrame and perform a basic operation to save csv on disk.\n","\n","_Note_: You must import nvstrings and nvcategory before cudf, else you'll get errors."]},{"cell_type":"code","metadata":{"id":"EwaJSKuswsNi","colab_type":"code","colab":{}},"source":["import cudf\n","import time\n","\n","# read CSV from file\n","start = time.time()\n","df = cudf.read_csv('/content/teste.csv')\n","df.to_csv('/content/testdde.csv')\n","print('seconds: {}'.format(time.time()-start))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7f37YFbyz0j_","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import time\n","\n","start = time.time()\n","df = pd.read_csv('test.csv')\n","df.to_csv('pandasdf.csv')\n","print('seconds: {}'.format(time.time()-start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJgZNBuc8HFH","colab_type":"text"},"source":["# Start Spark Session"]},{"cell_type":"code","metadata":{"id":"2nRUWDC1k3CS","colab_type":"code","colab":{}},"source":["# only for exits the folder\n","!rm -rf sparkdf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYNpl2Wz8GRb","colab_type":"code","colab":{}},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","import time\n","\n","spark = SparkSession.builder.master(\"local[*]\").config('spark.executor.memory','8g').getOrCreate()\n","\n","# Use spark\n","start = time.time()\n","df = spark.read.format('csv').options(header='true', inferSchema='true').load('test.csv')\n","df.write.option(\"header\",\"true\").csv(\"sparkdf\")\n","print('seconds: {}'.format(time.time()-start))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZOW0O8KmROG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}